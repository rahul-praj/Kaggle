{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-28T13:31:51.486761Z","iopub.execute_input":"2023-09-28T13:31:51.488165Z","iopub.status.idle":"2023-09-28T13:31:51.927294Z","shell.execute_reply.started":"2023-09-28T13:31:51.488121Z","shell.execute_reply":"2023-09-28T13:31:51.926092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error\n\npd.options.display.max_rows = 100","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:31:51.929261Z","iopub.execute_input":"2023-09-28T13:31:51.929747Z","iopub.status.idle":"2023-09-28T13:31:55.345504Z","shell.execute_reply.started":"2023-09-28T13:31:51.929716Z","shell.execute_reply":"2023-09-28T13:31:55.344254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:31:55.348442Z","iopub.execute_input":"2023-09-28T13:31:55.349517Z","iopub.status.idle":"2023-09-28T13:31:55.446000Z","shell.execute_reply.started":"2023-09-28T13:31:55.349473Z","shell.execute_reply":"2023-09-28T13:31:55.444894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test.head())","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:31:55.448465Z","iopub.execute_input":"2023-09-28T13:31:55.448850Z","iopub.status.idle":"2023-09-28T13:31:55.478193Z","shell.execute_reply.started":"2023-09-28T13:31:55.448819Z","shell.execute_reply":"2023-09-28T13:31:55.477020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split training data into predictors and price (output)\nx_train = train.iloc[:, 1:-1]\ny_train = train.iloc[:, -1]\nx_train","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:31:55.479835Z","iopub.execute_input":"2023-09-28T13:31:55.482753Z","iopub.status.idle":"2023-09-28T13:31:55.525878Z","shell.execute_reply.started":"2023-09-28T13:31:55.482702Z","shell.execute_reply":"2023-09-28T13:31:55.524532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.drop(labels='Id', axis=1, inplace=True)\ntest","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:31:55.527462Z","iopub.execute_input":"2023-09-28T13:31:55.527865Z","iopub.status.idle":"2023-09-28T13:31:55.573528Z","shell.execute_reply.started":"2023-09-28T13:31:55.527836Z","shell.execute_reply":"2023-09-28T13:31:55.572212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([x_train, test])\ndf.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:31:55.575061Z","iopub.execute_input":"2023-09-28T13:31:55.575465Z","iopub.status.idle":"2023-09-28T13:31:55.592057Z","shell.execute_reply.started":"2023-09-28T13:31:55.575434Z","shell.execute_reply":"2023-09-28T13:31:55.590531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:31:55.594351Z","iopub.execute_input":"2023-09-28T13:31:55.594801Z","iopub.status.idle":"2023-09-28T13:31:55.604949Z","shell.execute_reply.started":"2023-09-28T13:31:55.594769Z","shell.execute_reply":"2023-09-28T13:31:55.603590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes.head(80)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:31:55.607034Z","iopub.execute_input":"2023-09-28T13:31:55.607497Z","iopub.status.idle":"2023-09-28T13:31:55.630023Z","shell.execute_reply.started":"2023-09-28T13:31:55.607464Z","shell.execute_reply":"2023-09-28T13:31:55.628360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Subclass should be a qualitative variable, and needs to be changed to an object","metadata":{}},{"cell_type":"code","source":"df['MSSubClass'] = df.MSSubClass.astype(str)\nprint(df.dtypes)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:31:55.636909Z","iopub.execute_input":"2023-09-28T13:31:55.637388Z","iopub.status.idle":"2023-09-28T13:31:55.652224Z","shell.execute_reply.started":"2023-09-28T13:31:55.637353Z","shell.execute_reply":"2023-09-28T13:31:55.651014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Address Missing Values","metadata":{}},{"cell_type":"code","source":"df.isna().sum().sort_values(ascending=False).head(35)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:31:55.653436Z","iopub.execute_input":"2023-09-28T13:31:55.654587Z","iopub.status.idle":"2023-09-28T13:31:55.690408Z","shell.execute_reply.started":"2023-09-28T13:31:55.654494Z","shell.execute_reply":"2023-09-28T13:31:55.689513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Almost all values in the Pool Quality/ Condition feature are missing, therefore feature will be dropped (pool area can be indicative of whether house has a pool)","metadata":{}},{"cell_type":"code","source":"print(df.MiscFeature.value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:31:55.691485Z","iopub.execute_input":"2023-09-28T13:31:55.691817Z","iopub.status.idle":"2023-09-28T13:31:55.702613Z","shell.execute_reply.started":"2023-09-28T13:31:55.691782Z","shell.execute_reply":"2023-09-28T13:31:55.701292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### The miscellaneous features indicate additional features where relevant, so can keep in the dataset","metadata":{}},{"cell_type":"markdown","source":"### Assign numeric ratings to columns with ranked values","metadata":{}},{"cell_type":"code","source":"# Check if 'TA' is in the dataframe column. We'll take the columns in which evaluations exist and map them to ratings\ncols = []\n\nfor column in df.columns:\n    if 'TA' in df[column].values:\n        cols.append(column)\n\n# Assign ratings to the relevant columns\n\nratings_map = {np.nan: 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\ndf[cols] = df[cols].replace(ratings_map)\ndf","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:31:55.704517Z","iopub.execute_input":"2023-09-28T13:31:55.704957Z","iopub.status.idle":"2023-09-28T13:31:55.797523Z","shell.execute_reply.started":"2023-09-28T13:31:55.704919Z","shell.execute_reply":"2023-09-28T13:31:55.796405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Categorical Missing Value Imputation","metadata":{}},{"cell_type":"code","source":"cat_nulls = df.loc[:, df.isna().sum() > 0].select_dtypes(\"object\")\ncat_nulls.isna().sum().sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:31:55.799394Z","iopub.execute_input":"2023-09-28T13:31:55.799766Z","iopub.status.idle":"2023-09-28T13:31:55.835925Z","shell.execute_reply.started":"2023-09-28T13:31:55.799736Z","shell.execute_reply":"2023-09-28T13:31:55.834968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# In context, null values provide information about the dwelling, so null values do not need to be removed. For the missing zoning values, we can fill missing values by taking the most common land zone in the neighborhood\ndef mode_fill(data, feature, comparison_feature):\n    data[feature] = data.apply(lambda row: data[data[comparison_feature] == row[comparison_feature]][feature].mode().iat[0] if pd.isna(row[feature]) else row[feature] if not data[data[comparison_feature] == row[comparison_feature]][feature].mode().empty else row[feature], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:31:55.837401Z","iopub.execute_input":"2023-09-28T13:31:55.837818Z","iopub.status.idle":"2023-09-28T13:31:55.846481Z","shell.execute_reply.started":"2023-09-28T13:31:55.837790Z","shell.execute_reply":"2023-09-28T13:31:55.845309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"elec_chi2 = pd.DataFrame(index=cat_nulls.loc[:, cat_nulls.columns != 'Electrical'].columns, columns=['chi2', 'pval'])\n\nfor feature in cat_nulls.loc[:, cat_nulls.columns != 'Electrical'].columns:\n    crosstab = pd.crosstab(cat_nulls.Electrical, cat_nulls[feature])\n    chi2, pval, dof, expected = scipy.stats.chi2_contingency(crosstab)\n    elec_chi2.loc[feature, 'chi2'] = chi2\n    elec_chi2.loc[feature, 'pval'] = pval\n    \nelec_chi2.sort_values(by='chi2', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:31:55.847587Z","iopub.execute_input":"2023-09-28T13:31:55.847912Z","iopub.status.idle":"2023-09-28T13:31:56.060519Z","shell.execute_reply.started":"2023-09-28T13:31:55.847886Z","shell.execute_reply":"2023-09-28T13:31:56.059024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utilities_chi2 = pd.DataFrame(index=cat_nulls.loc[:, cat_nulls.columns != 'Utilities'].columns, columns=['chi2', 'pval'])\n\nfor feature in cat_nulls.loc[:, cat_nulls.columns != 'Utilities'].columns:\n    crosstab = pd.crosstab(cat_nulls.Utilities, cat_nulls[feature])\n    chi2, pval, dof, expected = scipy.stats.chi2_contingency(crosstab)\n    utilities_chi2.loc[feature, 'chi2'] = chi2\n    utilities_chi2.loc[feature, 'pval'] = pval\n    \nutilities_chi2.sort_values(by='chi2', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:31:56.062388Z","iopub.execute_input":"2023-09-28T13:31:56.062739Z","iopub.status.idle":"2023-09-28T13:31:56.256958Z","shell.execute_reply.started":"2023-09-28T13:31:56.062711Z","shell.execute_reply":"2023-09-28T13:31:56.255752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mode_fill(df, 'MSZoning', 'Neighborhood')\nmode_fill(df, 'Electrical', 'Exterior1st')\nmode_fill(df, 'Utilities', 'Electrical')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:31:56.258635Z","iopub.execute_input":"2023-09-28T13:31:56.259100Z","iopub.status.idle":"2023-09-28T13:32:26.397134Z","shell.execute_reply.started":"2023-09-28T13:31:56.259070Z","shell.execute_reply":"2023-09-28T13:32:26.395693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the remaining categorical features, we can fill the null values to identify them as \"Not Applicable\", as it is reflective of a household feature not existing","metadata":{}},{"cell_type":"code","source":"cat_nulls = cat_nulls.fillna(\"Not Applicable\")\nfor col in cat_nulls:\n    df[col] = cat_nulls[col]\n    \ncat_nulls.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:32:26.398730Z","iopub.execute_input":"2023-09-28T13:32:26.399610Z","iopub.status.idle":"2023-09-28T13:32:26.428137Z","shell.execute_reply.started":"2023-09-28T13:32:26.399577Z","shell.execute_reply":"2023-09-28T13:32:26.426800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Numeric Missing Value Imputation","metadata":{}},{"cell_type":"code","source":"df.isna().sum().sort_values(ascending=False).head(15)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:32:26.429683Z","iopub.execute_input":"2023-09-28T13:32:26.430013Z","iopub.status.idle":"2023-09-28T13:32:26.457995Z","shell.execute_reply.started":"2023-09-28T13:32:26.429986Z","shell.execute_reply":"2023-09-28T13:32:26.456520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Lot frontage should apply to most residencies, and therefore we'll use a regression analysis to determine this. To do this, we'll first plot the lot frontage values against the lot areas","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(data=df, x=df[df.LotFrontage.isna() == False].LotArea, y=df[df.LotFrontage.isna() == False].LotFrontage, alpha=0.4)\nplt.xlim(0, 50000)\nplt.show()\nplt.clf()\n\nprint(f\"Correlation between frontage and area: {scipy.stats.pearsonr(df[df.LotFrontage.isna() == False].LotArea, df[df.LotFrontage.isna() == False].LotFrontage)[0]}\")\nprint(f\"P-val of correlation between frontage and area: {scipy.stats.pearsonr(df[df.LotFrontage.isna() == False].LotArea, df[df.LotFrontage.isna() == False].LotFrontage)[1]}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:32:26.459644Z","iopub.execute_input":"2023-09-28T13:32:26.459990Z","iopub.status.idle":"2023-09-28T13:32:26.832208Z","shell.execute_reply.started":"2023-09-28T13:32:26.459962Z","shell.execute_reply":"2023-09-28T13:32:26.831150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lot_reg = LinearRegression()\nlot_reg.fit(np.array(df[df.LotFrontage.isna() == False].LotArea).reshape(-1, 1), np.array(df[df.LotFrontage.isna() == False].LotFrontage).reshape(-1, 1))\nfrontage_pred = lot_reg.predict(np.array(df[df.LotFrontage.isna() == True].LotArea).reshape(-1, 1))\n\ncount = 0\nfrontage_pred = frontage_pred.flatten().tolist()\n\nfor index, row in df.iterrows():\n    if pd.isna(row['LotFrontage']):\n        df.loc[index, 'LotFrontage'] = frontage_pred[count]\n        count += 1\n\nprint(df.LotFrontage.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:32:26.833620Z","iopub.execute_input":"2023-09-28T13:32:26.833933Z","iopub.status.idle":"2023-09-28T13:32:27.181418Z","shell.execute_reply.started":"2023-09-28T13:32:26.833908Z","shell.execute_reply":"2023-09-28T13:32:27.180222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### For the remaining missing values, we can fill the values to be 0","metadata":{}},{"cell_type":"code","source":"df = df.fillna(0)\ndf.isna().sum().sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:32:27.183240Z","iopub.execute_input":"2023-09-28T13:32:27.184018Z","iopub.status.idle":"2023-09-28T13:32:27.231173Z","shell.execute_reply.started":"2023-09-28T13:32:27.183976Z","shell.execute_reply":"2023-09-28T13:32:27.229930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"##### Plot distributions for numerical features, to check for any standardization required","metadata":{}},{"cell_type":"code","source":"skew_df = pd.DataFrame(index=df.select_dtypes(np.number).columns, columns=['skewness'])\n\nfor count, feature in enumerate(df.select_dtypes(np.number).columns):\n    skew_df.iloc[count, 0] = abs(scipy.stats.skew(df[feature]))\n\nskew_df = skew_df[skew_df['skewness'] > 1].sort_values(by='skewness', ascending=False)\nskew_df","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:32:27.232650Z","iopub.execute_input":"2023-09-28T13:32:27.232980Z","iopub.status.idle":"2023-09-28T13:32:27.304414Z","shell.execute_reply.started":"2023-09-28T13:32:27.232945Z","shell.execute_reply":"2023-09-28T13:32:27.303060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the distribution of highly skewed features\n\ncount = 1\nfig = plt.figure(figsize=(15, 12))\n\nfor feature in skew_df.index:\n    plt.subplot(8, 3, count)\n    sns.histplot(data=df, x=feature, kde=True)\n    plt.title(f\"{feature} distribution\")\n    \n    count += 1\n\nplt.tight_layout()\nplt.show()\nplt.clf()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:32:27.306020Z","iopub.execute_input":"2023-09-28T13:32:27.306411Z","iopub.status.idle":"2023-09-28T13:32:37.521791Z","shell.execute_reply.started":"2023-09-28T13:32:27.306381Z","shell.execute_reply":"2023-09-28T13:32:37.520716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply yeo johnson transformation for each feature\ntransformed_df = pd.DataFrame(columns=skew_df.index)\nfig = plt.figure(figsize=(15, 12))\ncount = 1\n\nfor i in transformed_df.columns:\n    transformed_df[i], lambda_ = scipy.stats.yeojohnson(df[i])\n\n    plt.subplot(8, 3, count)\n    sns.histplot(data=transformed_df, x=i, kde=True)\n    plt.title(f\"{i} transformed distribution\")\n    \n    count += 1\n    \n    df[i] = transformed_df[i]\n    \n\nplt.tight_layout()\nplt.show()\nplt.clf()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:32:37.523656Z","iopub.execute_input":"2023-09-28T13:32:37.524375Z","iopub.status.idle":"2023-09-28T13:32:46.621775Z","shell.execute_reply.started":"2023-09-28T13:32:37.524333Z","shell.execute_reply":"2023-09-28T13:32:46.620290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Draw a heatmap for numeric feature correlation","metadata":{}},{"cell_type":"code","source":"f,ax = plt.subplots(figsize=(25,25))\nplt.title('Correlation Matrix')\nsns.heatmap(df.select_dtypes(np.number).corr(method='pearson').corr(method='pearson'), annot=True, fmt = '.2f', ax=ax, vmin=-1, cmap='coolwarm_r')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:32:46.623543Z","iopub.execute_input":"2023-09-28T13:32:46.623919Z","iopub.status.idle":"2023-09-28T13:32:52.961425Z","shell.execute_reply.started":"2023-09-28T13:32:46.623890Z","shell.execute_reply":"2023-09-28T13:32:52.959384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transform remaining categorical variables","metadata":{}},{"cell_type":"markdown","source":"##### Since one-hot encoding does not do any favours with respect to dimensionality, target encoding will be used to encode categorical variables","metadata":{}},{"cell_type":"code","source":"def cat_encode(data, target, col):\n    trained = pd.concat([data.iloc[0:1460, :], target], axis=1)\n    grouped = trained.groupby(by=col).agg({'SalePrice': 'mean'}).reset_index()\n    grouped = grouped.sort_values(by=grouped.columns[1], ascending=True)\n    \n    grouped_dict = {col: {row.iloc[0]: row.iloc[1] for index, row in grouped.iterrows()}}\n    print(grouped_dict)\n    plt.figure(figsize=(20, 6))\n    plt.subplot(1, 2, 1)\n    sns.countplot(data=data, y=col)\n    plt.title(f\"{col} countplot\")\n    \n    data[col] = data[col].map(grouped_dict[col])\n    \n    plt.subplot(1, 2, 2)\n    sns.lineplot(data=grouped, x=grouped.iloc[:, 0], y=grouped.iloc[:, 1])\n    plt.title(f\"{col} distribution\")\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:32:52.967098Z","iopub.execute_input":"2023-09-28T13:32:52.967872Z","iopub.status.idle":"2023-09-28T13:32:52.978615Z","shell.execute_reply.started":"2023-09-28T13:32:52.967835Z","shell.execute_reply":"2023-09-28T13:32:52.977371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = df.copy(deep=True)\nfor column in df2.select_dtypes(\"object\"):\n    cat_encode(df2, y_train, column)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:32:52.980279Z","iopub.execute_input":"2023-09-28T13:32:52.980662Z","iopub.status.idle":"2023-09-28T13:33:12.218552Z","shell.execute_reply.started":"2023-09-28T13:32:52.980631Z","shell.execute_reply":"2023-09-28T13:33:12.216690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Scale the data","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\ndf3 = pd.DataFrame(scaler.fit_transform(df2), columns=df2.columns)\ndf3","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:33:12.220000Z","iopub.execute_input":"2023-09-28T13:33:12.220370Z","iopub.status.idle":"2023-09-28T13:33:12.271876Z","shell.execute_reply.started":"2023-09-28T13:33:12.220336Z","shell.execute_reply":"2023-09-28T13:33:12.270396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = df3.iloc[0:1460, :]\nx_test = df3.iloc[1460:, :]","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:33:12.273267Z","iopub.execute_input":"2023-09-28T13:33:12.273638Z","iopub.status.idle":"2023-09-28T13:33:12.280360Z","shell.execute_reply.started":"2023-09-28T13:33:12.273610Z","shell.execute_reply":"2023-09-28T13:33:12.279065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Target Transformation ","metadata":{}},{"cell_type":"code","source":"sns.histplot(y_train, kde=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:35:27.224729Z","iopub.execute_input":"2023-09-28T13:35:27.225133Z","iopub.status.idle":"2023-09-28T13:35:27.712646Z","shell.execute_reply.started":"2023-09-28T13:35:27.225103Z","shell.execute_reply":"2023-09-28T13:35:27.711134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### To make the distribution normal, we'll use log tranformation. First check that there are no 0's in the target feature, as log transformation cannot be applied to these","metadata":{}},{"cell_type":"code","source":"print(min(y_train))","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:37:07.420134Z","iopub.execute_input":"2023-09-28T13:37:07.421217Z","iopub.status.idle":"2023-09-28T13:37:07.427766Z","shell.execute_reply.started":"2023-09-28T13:37:07.421177Z","shell.execute_reply":"2023-09-28T13:37:07.426142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_new = np.log(y_train)\n\nsns.histplot(y_train_new, kde=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:37:49.242567Z","iopub.execute_input":"2023-09-28T13:37:49.242972Z","iopub.status.idle":"2023-09-28T13:37:49.684605Z","shell.execute_reply.started":"2023-09-28T13:37:49.242942Z","shell.execute_reply":"2023-09-28T13:37:49.683143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ml_modelling:\n    def __init__(self, x_train, y_train, x_test):\n        self.x = x_train\n        self.y = y_train\n        self.x_test = x_test\n        self.dict = {}\n        \n    def linear(self, components):\n        mean = self.x.mean(axis=0)\n        sttd = self.x.std(axis=0)\n        data_standardized = (self.x - mean) / sttd\n        \n        pca = PCA(n_components=components)\n        pca_x = pca.fit_transform(data_standardized)\n        \n        lr = LinearRegression()\n        lr_scores = -cross_val_score(lr, pca_x, self.y, cv=5, scoring='neg_mean_squared_error')\n        lr_score = lr_scores.mean()\n        self.dict['Linear Regression'] = lr_score\n        \n        self.pca_x = pca_x\n        self.lr = lr\n        \n        return lr_score\n    \n    def random_forest(self):\n        rfr = RandomForestRegressor(self.x, self.y)\n        rfr_scores = -cross_val_score(rfr, self.x, self.y, cv=5, scoring='neg_mean_squared_error')\n        rfr_score = rfr_scores.mean()\n        self.dict['Random Forest'] = rfr_score\n                \n        self.rfr = rfr\n        \n        return rfr_score\n    \n    def xgb(self):\n        xgb = XGBRegressor()\n        xgb_scores = -cross_val_score(xgb, self.x, self.y, cv=5, scoring='neg_mean_squared_error')\n        xgb_score = xgb_scores.mean()\n        self.dict['XG Boost'] = xgb_score\n        \n        self.xgb = xgb\n        \n        return xgb_score\n    \n    def lgbm(self):\n        lgbm = LGBMRegressor()\n        lgbm_scores = -cross_val_score(lgbm, self.x, self.y, cv=5, scoring='neg_mean_squared_error')\n        lgbm_score = lgbm_scores.mean()\n        self.dict['Light GBM'] = lgbm_score\n        \n        self.lgbm = lgbm\n        \n        return lgbm_score\n    \n    def ensemble(self):\n        # Generate predictions from base models\n        models = [self.lr, self.rfr, self.xgb, self.lgbm]\n        \n        base_model_predictions = [model.predict(self.x) for model in models]\n\n        # Stack the predictions and use a meta-model\n        stacked_X = np.vstack(base_model_predictions).T\n        meta_model = LinearRegression()\n        meta_model.fit(stacked_X, self.y)\n\n        # Optimize meta-model weights using cross-validation\n#         stacked_predictions = np.vstack([model.predict(self.x_test) for model in models]).T\n        best_weights = cross_val_predict(meta_model, stacked_X, self.y, cv=5)\n        \n        y_pred = (\n            best_weights[0] * self.lr.predict(self.pca_x) +\n            best_weights[1] * self.rfr.predict(self.x) +\n            best_weights[2] * self.xgb.predict(self.x) +\n            best_weights[3] * self.lgbm.predict(self.x)\n)\n        \n        \n        \n        \n    \n    \n        \n                    ","metadata":{},"execution_count":null,"outputs":[]}]}